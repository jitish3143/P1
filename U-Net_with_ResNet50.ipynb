{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ResNet50-U-Net",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLet41Rl4ZGh",
        "outputId": "a2e3352a-b94a-4279-ca18-2be303269c3b"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Apr 29 13:35:35 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKJ-MSCi4ZDq",
        "outputId": "c67a85a4-586f-491b-dc4a-5d499f61d4a0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2cbXJW4uJZW"
      },
      "source": [
        "Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSrSSS_5-9GS"
      },
      "source": [
        "# concatenate version of U-net with ResNet-50 encoder\n",
        "import torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import numpy \n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "from torchvision.transforms import ToTensor\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np \n",
        "from torchvision import transforms\n",
        "import imageio\n",
        "from imageio import imread\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "resnet = torchvision.models.resnet.resnet50(pretrained=True)\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Helper module that consists of a Conv -> BN -> ReLU\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, padding=1, kernel_size=3, stride=1, with_nonlinearity=True):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, padding=padding, kernel_size=kernel_size, stride=stride)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU() #nn.LeakyReLU()  #\n",
        "        self.with_nonlinearity = with_nonlinearity\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        if self.with_nonlinearity:\n",
        "            x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "class out(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, padding=1, kernel_size=3, stride=1, with_nonlinearity=True):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, padding=padding, kernel_size=kernel_size, stride=stride)\n",
        "        self.conv2 = nn.Conv2d(32, out_channels, padding=padding, kernel_size=kernel_size, stride=stride)\n",
        "        self.out = nn.Conv2d(32, 3, padding=padding, kernel_size=3, stride=stride)\n",
        "        # self.dropout = nn.Dropout(0.4)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.with_nonlinearity = with_nonlinearity\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.conv2(x)\n",
        "        # x = self.dropout(x)\n",
        "        x = self.out(x)\n",
        "        if self.with_nonlinearity:\n",
        "            x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Bridge(nn.Module):\n",
        "    \"\"\"\n",
        "    This is the middle layer of the UNet which just consists of some conv blocks\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.bridge = nn.Sequential(\n",
        "            ConvBlock(in_channels, out_channels),\n",
        "            ConvBlock(out_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.bridge(x)\n",
        "\n",
        "\n",
        "class UpBlockForUNetWithResNet50(nn.Module):\n",
        "    \"\"\"\n",
        "    Up block that encapsulates one up-sampling step which consists of Upsample -> ConvBlock -> ConvBlock\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, up_conv_in_channels=None, up_conv_out_channels=None,\n",
        "                 upsampling_method=\"conv_transpose\"):\n",
        "        super().__init__()\n",
        "\n",
        "        if up_conv_in_channels == None:\n",
        "            up_conv_in_channels = in_channels\n",
        "        if up_conv_out_channels == None:\n",
        "            up_conv_out_channels = out_channels\n",
        "\n",
        "        if upsampling_method == \"conv_transpose\":\n",
        "            self.upsample = nn.ConvTranspose2d(up_conv_in_channels, up_conv_out_channels, kernel_size=2, stride=2)\n",
        "        elif upsampling_method == \"bilinear\":\n",
        "            self.upsample = nn.Sequential(\n",
        "                nn.Upsample(mode='bilinear', scale_factor=2),\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
        "            )\n",
        "        self.conv_block_1 = ConvBlock(in_channels, out_channels)\n",
        "        self.conv_block_2 = ConvBlock(out_channels, out_channels)\n",
        "\n",
        "    def forward(self, up_x, down_x):\n",
        "        \"\"\"\n",
        "        :param up_x: this is the output from the previous up block\n",
        "        :param down_x: this is the output from the down block\n",
        "        :return: upsampled feature map\n",
        "        \"\"\"\n",
        "        x = self.upsample(up_x)\n",
        "        x = torch.cat([x, down_x], 1)\n",
        "        x = self.conv_block_1(x)\n",
        "        x = self.conv_block_2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class UNetWithResnet50Encoder(nn.Module):\n",
        "    DEPTH = 6\n",
        "\n",
        "    def __init__(self, n_classes=256):\n",
        "        super().__init__()\n",
        "        resnet = torchvision.models.resnet.resnet50(pretrained=True) # Loading the pre trained resnet\n",
        "        down_blocks = []  # encodes blocks or downsampling blocks\n",
        "        up_blocks = []  # decoder part of upsampling blocks \n",
        "        self.input_block = nn.Sequential(*list(resnet.children()))[:3]  # input layers or resnet or encoder layers\n",
        "        self.input_pool = list(resnet.children())[3]  # encoder max pooling layer\n",
        "        for bottleneck in list(resnet.children()):\n",
        "            if isinstance(bottleneck, nn.Sequential):\n",
        "                down_blocks.append(bottleneck)\n",
        "     \n",
        "        self.down_blocks = nn.ModuleList(down_blocks)  # just getting the down sampling layers/encoder layers from resnet\n",
        "\n",
        "        self.bridge = Bridge(4096, 2048)\n",
        "\n",
        "        up_blocks.append(UpBlockForUNetWithResNet50(2048, 1024))\n",
        "        up_blocks.append(UpBlockForUNetWithResNet50(1024, 512))\n",
        "        up_blocks.append(UpBlockForUNetWithResNet50(512, 256))\n",
        "        up_blocks.append(UpBlockForUNetWithResNet50(in_channels=128 + 64, out_channels=128,\n",
        "                                                    up_conv_in_channels=256, up_conv_out_channels=128))\n",
        "        up_blocks.append(UpBlockForUNetWithResNet50(in_channels=64 + 3, out_channels=64,\n",
        "                                                    up_conv_in_channels=128, up_conv_out_channels=64))\n",
        "\n",
        "        self.up_blocks = nn.ModuleList(up_blocks) # got the upsampling or the decoder layers\n",
        "\n",
        "        self.out = out(64, 32)\n",
        "\n",
        "    def forward(self, x,y, with_output_feature_map=False):  # here we are making the network\n",
        "        pre_pools = dict()\n",
        "        pre_pools[f\"layer_0\"] = x\n",
        "        x = self.input_block(x)  # taking the input block and storing in x\n",
        "        pre_pools[f\"layer_1\"] = x # the input block is now stored as layer 1\n",
        "        x = self.input_pool(x)  #  taking the max_pool now \n",
        "\n",
        "        # constrcuting the encoder part\n",
        "        for i, block in enumerate(self.down_blocks, 2):  # for all the down blocks \n",
        "            x = block(x)\n",
        "            if i == (UNetWithResnet50Encoder.DEPTH - 1):\n",
        "                continue\n",
        "            pre_pools[f\"layer_{i}\"] = x  ## creating all the down sampling layers\n",
        "\n",
        "\n",
        "        pre_pools_inp2 = dict()\n",
        "        pre_pools_inp2[f\"layer_0\"] = y\n",
        "        y = self.input_block(y)  # taking the input block and storing in x\n",
        "        pre_pools_inp2[f\"layer_1\"] = y # the input block is now stored as layer 1\n",
        "        y = self.input_pool(y)  #  taking the max_pool now \n",
        "\n",
        "\n",
        "        for i, block in enumerate(self.down_blocks, 2):  # for all the down blocks \n",
        "            y = block(y)\n",
        "            if i == (UNetWithResnet50Encoder.DEPTH - 1):\n",
        "                continue\n",
        "            pre_pools_inp2[f\"layer_{i}\"] = y  ## creating all the down sampling layers\n",
        "\n",
        "        # concatenating the encoder outputs\n",
        "        x = torch.cat([x,y],1)\n",
        "\n",
        "        # constructing the bridge between encoder and decoder\n",
        "        x = self.bridge(x)  # this is the bridge between down sampling and up sampling \n",
        "\n",
        "        # decoder and output block\n",
        "        for i, block in enumerate(self.up_blocks, 1):\n",
        "            key = f\"layer_{UNetWithResnet50Encoder.DEPTH - 1 - i}\"  # now using that bridge for upsampling f\n",
        "            x = block(x, pre_pools[key])\n",
        "        output_feature_map = x\n",
        "        x = self.out(x)\n",
        "        del pre_pools\n",
        "        del pre_pools_inp2\n",
        "        if with_output_feature_map:\n",
        "            return x, output_feature_map\n",
        "        else:\n",
        "            return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmlMPntsuZiD"
      },
      "source": [
        "Applying tranformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN1GxADp_FxD"
      },
      "source": [
        "from skimage.io import imread\n",
        "from torch.utils import data\n",
        "from tqdm import tqdm\n",
        "\n",
        "# converting the data to the tensors \n",
        "class SegmentationDataSet(data.Dataset):\n",
        "    def __init__(self,\n",
        "                 inputs: list,\n",
        "                 targets: list,\n",
        "                 originals: list,\n",
        "                 transform=None,\n",
        "                 use_cache=False,\n",
        "                 pre_transform=None,\n",
        "                 ):\n",
        "        self.inputs = inputs\n",
        "        self.targets = targets\n",
        "        self.originals = originals\n",
        "        self.transform = transform\n",
        "        self.inputs_dtype = torch.float32\n",
        "        self.targets_dtype = torch.float32\n",
        "        self.use_cache = use_cache\n",
        "        self.pre_transform = pre_transform\n",
        "\n",
        "        # caching the data to reduce training time\n",
        "        if self.use_cache:\n",
        "            self.cached_data = []\n",
        "\n",
        "            progressbar = tqdm(range(len(self.inputs)), desc='Caching')\n",
        "            for i, img_name, tar_name, org_name in zip(progressbar, self.inputs, self.targets,self.originals):\n",
        "                img= Image.open(img_name)\n",
        "                tar = Image.open(tar_name) \n",
        "                org = Image.open(org_name)\n",
        "                if self.pre_transform is not None:\n",
        "                    img = self.pre_transform(img)\n",
        "                    tar = self.pre_transform(tar)\n",
        "                    org = self.pre_transform(org)\n",
        "                self.cached_data.append((img, tar, org))\n",
        "                \n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self,\n",
        "                    index: int):\n",
        "        if self.use_cache:\n",
        "            x, y, z = self.cached_data[index]\n",
        "        else:\n",
        "            # Select the sample\n",
        "            input_ID = self.inputs[index]\n",
        "            target_ID = self.targets[index]\n",
        "            org_ID = self.originals[index]\n",
        "            # Load input and target\n",
        "            x, y, z = imread(input_ID), imread(target_ID), imread(org_ID)\n",
        "\n",
        "        # Preprocessing\n",
        "        if self.transform is not None:\n",
        "            x, y = self.transform(image=x)['image'], y\n",
        "        return x, y, z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91flETpFum8v"
      },
      "source": [
        "Training Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cHQP2zn_ImE"
      },
      "source": [
        "# training functions \n",
        "from math import exp\n",
        "\n",
        "class LogCoshLoss(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self,yt, yt_prime):\n",
        "    e_y = yt - yt_prime\n",
        "    return torch.mean(torch.log(torch.cosh(e_y + 1e-12)))\n",
        "\n",
        "# Trainer function\n",
        "class Trainer:\n",
        "    def __init__(self,\n",
        "                 model: torch.nn.Module,\n",
        "                 device: torch.device,\n",
        "                 criterion: torch.nn.Module,\n",
        "                 optimizer: torch.optim.Optimizer,\n",
        "                 training_DataLoader: torch.utils.data.Dataset,\n",
        "                 validation_DataLoader: torch.utils.data.Dataset = None,\n",
        "                 lr_scheduler: torch.optim.lr_scheduler = None,\n",
        "                 epochs: int = 100,\n",
        "                 accum_iter: int = 1,\n",
        "                 verbose_step: int = 1,\n",
        "                 EarlyStopping: int = 5,\n",
        "                 notebook: bool = False,\n",
        "                 schd_batch_update: bool =False\n",
        "                 ):\n",
        "\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.lr_scheduler = lr_scheduler\n",
        "        self.training_DataLoader = training_DataLoader\n",
        "        self.validation_DataLoader = validation_DataLoader\n",
        "        self.device = device\n",
        "        self.epochs = epochs\n",
        "        self.notebook = notebook\n",
        "        self.accum_iter = accum_iter\n",
        "        self.schd_batch_update = schd_batch_update\n",
        "        self.verbose_step = verbose_step\n",
        "        self.EarlyStopping = EarlyStopping\n",
        "\n",
        "        self.training_loss = []\n",
        "        self.validation_loss = []\n",
        "        self.learning_rate = []\n",
        "        self.loss_min = 999999\n",
        "        self.epoch = 0\n",
        "\n",
        "    def run_trainer(self):\n",
        "\n",
        "        if self.notebook:\n",
        "            from tqdm.notebook import tqdm, trange\n",
        "        else:\n",
        "            from tqdm import tqdm, trange\n",
        "\n",
        "        progressbar = trange(self.epochs, desc='Progress')\n",
        "        not_improving = 0\n",
        "        for i in progressbar:\n",
        "            \"\"\"Epoch counter\"\"\"\n",
        "            self.epoch += 1  # epoch counter\n",
        "\n",
        "            \"\"\"Training block\"\"\"\n",
        "            self._train()\n",
        "\n",
        "            \"\"\"Validation block\"\"\"\n",
        "            if self.validation_DataLoader is not None:\n",
        "                self._validate()\n",
        "                not_improving += 1\n",
        "\n",
        "            if self.validation_loss[-1]<self.loss_min:\n",
        "                print(f'val_loss_min ({self.loss_min:.4f} --> {self.validation_loss[-1]:.4f}). Saving model ...')\n",
        "                self.loss_min = self.validation_loss[-1]\n",
        "                not_improving = 0\n",
        "                torch.save({\n",
        "                    'epoch': self.epoch,\n",
        "                    'model_state_dict': self.model.state_dict(),\n",
        "                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "                    'loss': self.criterion,\n",
        "                     }, '/content/drive/MyDrive/Checkpoints/StyleTransferByUnet.pth')\n",
        "                print('-----------------------------------------------------------')\n",
        "\n",
        "            # applying early stopping to the model\n",
        "            if not_improving == self.EarlyStopping:\n",
        "                print('Early Stopping...')\n",
        "                return self.training_loss, self.validation_loss, self.learning_rate\n",
        "\n",
        "            # \"\"\"Learning rate scheduler block\"\"\"\n",
        "            # if self.lr_scheduler is not None:\n",
        "            #     if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':\n",
        "            #         self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss\n",
        "            #     else:\n",
        "            #         self.lr_scheduler.batch()  # learning rate scheduler step\n",
        "        return self.training_loss, self.validation_loss, self.learning_rate\n",
        "\n",
        "    # training part\n",
        "    def _train(self):\n",
        "\n",
        "        if self.notebook:\n",
        "            from tqdm.notebook import tqdm, trange\n",
        "        else:\n",
        "            from tqdm import tqdm, trange\n",
        "\n",
        "        running_loss = None\n",
        "        self.model.train()  # train mode\n",
        "        train_losses = []  # accumulate the losses here\n",
        "        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader))\n",
        "        for i, (x, y, z) in batch_iter:\n",
        "            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)\n",
        "            origin = z.to(self.device)\n",
        "\n",
        "            with autocast():\n",
        "                out = self.model(input,target)  # one forward pass\n",
        "              \n",
        "                # out loss function is based on the input value since that's the final result we want\n",
        "                loss = self.criterion(out, origin)  # calculate loss\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            if running_loss is None:\n",
        "                running_loss = loss.item()\n",
        "            else:\n",
        "                running_loss = running_loss * .95 + loss.item() * .05\n",
        "            train_losses.append(loss.item())\n",
        "            # loss.backward()  # one backward pass\n",
        "\n",
        "            if ((i + 1) %  self.accum_iter == 0) or ((i + 1) == len(self.training_DataLoader)):\n",
        "                # may unscale_ here if desired (e.g., to allow clipping unscaled gradients)\n",
        "                scaler.step(self.optimizer)  # update the parameters\n",
        "                scaler.update()\n",
        "                self.optimizer.zero_grad() \n",
        "\n",
        "                if self.lr_scheduler is not None and self.schd_batch_update:\n",
        "                   self.lr_scheduler.step()\n",
        "\n",
        "            if ((i + 1) % self.verbose_step == 0) or ((i + 1) == len(self.training_DataLoader)):\n",
        "                description = f'epoch {self.epoch} train loss: {running_loss:.4f}'\n",
        "\n",
        "                batch_iter.set_description(description)  # update progressbar\n",
        "\n",
        "            del input\n",
        "            del target\n",
        "            del origin\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        if self.lr_scheduler is not None and not self.schd_batch_update:\n",
        "            self.lr_scheduler.step()\n",
        "\n",
        "        self.training_loss.append(np.mean(train_losses))\n",
        "        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])\n",
        "\n",
        "        # batch_iter.close()\n",
        "\n",
        "    # validation part\n",
        "    def _validate(self):\n",
        "\n",
        "        if self.notebook:\n",
        "            from tqdm.notebook import tqdm, trange\n",
        "        else:\n",
        "            from tqdm import tqdm, trange\n",
        "\n",
        "        self.model.eval()  # evaluation mode\n",
        "        valid_losses = []  # accumulate the losses here\n",
        "        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader))\n",
        "\n",
        "        for i, (x, y, z) in batch_iter:\n",
        "            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)\n",
        "            origin = z.to(self.device)\n",
        "            with torch.no_grad():        \n",
        "                out = self.model(input,target)\n",
        "                loss = self.criterion(out, origin)\n",
        "                loss_value = loss.item()\n",
        "                valid_losses.append(loss_value)\n",
        "\n",
        "                batch_iter.set_description(f'epoch {self.epoch} validation {loss_value:.4f}')\n",
        "                del input\n",
        "                del target\n",
        "                del origin\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        self.validation_loss.append(np.mean(valid_losses))\n",
        "\n",
        "        # batch_iter.close()\n",
        "        torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uokb9OF-uqvD"
      },
      "source": [
        "Data Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueg_o9Mn_Js1"
      },
      "source": [
        "# pre processing\n",
        "from torch.utils.data import DataLoader\n",
        "import albumentations\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pathlib\n",
        "from torchvision import datasets, models, transforms\n",
        "import random\n",
        "# root directory\n",
        "root = pathlib.Path.cwd() / '/content/drive/MyDrive/Dataset_for_StyleTransferByUnet/training_set'\n",
        "root1 = pathlib.Path.cwd() / '/content/drive/MyDrive/Dataset_for_StyleTransferByUnet/validation_set'\n",
        "def get_filenames_of_path(path: pathlib.Path, ext: str = '*'):\n",
        "    \"\"\"Returns a list of files in a directory/path. Uses pathlib.\"\"\"\n",
        "    print(ext)\n",
        "    filenames = [file for file in path.glob(ext) if file.is_file()]\n",
        "    filenames.sort()   #= sorted(filenames)\n",
        "    print(filenames)\n",
        "    return filenames\n",
        "# input and target files\n",
        "inputs = get_filenames_of_path(root / 'train_new')\n",
        "targets = get_filenames_of_path(root / 'train_new2')\n",
        "originals = get_filenames_of_path(root / 'train_new1')\n",
        "\n",
        "validation_inputs = get_filenames_of_path(root1 / 'input')\n",
        "validation_targets = get_filenames_of_path(root1 / 'output')\n",
        "validation_originals = get_filenames_of_path(root1 / 'style')\n",
        "\n",
        "# resizing the data to 256x256\n",
        "pre_transforms = transforms.Compose([\n",
        "        transforms.Resize((256,256)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "def get_train_transforms():\n",
        "    return A.Compose([\n",
        "            # A.Cutout(),\n",
        "            A.OneOf([\n",
        "                A.IAAAdditiveGaussianNoise(scale=(0.01 * 255, 0.02 * 255)),\n",
        "                # A.GaussNoise(var_limit=(10.0, 25.0)),\n",
        "            ], p=0.66),\n",
        "            # A.OneOf([\n",
        "            #     A.MotionBlur(blur_limit=3),\n",
        "            #     A.MedianBlur(blur_limit=3),\n",
        "            #     A.Blur(blur_limit=3), \n",
        "            # ], p=0.66),\n",
        "            # A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.33),\n",
        "            # A.RandomGamma(gamma_limit=(90, 110)),\n",
        "            # A.CLAHE(clip_limit=1),\n",
        "            A.OneOf([\n",
        "                A.IAASharpen(alpha=(0.1, 0.3)),\n",
        "                A.IAAEmboss(alpha=(0.1, 0.4)),\n",
        "            ], p=0.66),\n",
        "        ], p=1.)\n",
        "\n",
        "# random seed\n",
        "random_seed = 42\n",
        "# split dataset into training set and validation set\n",
        "train_size = 0.8  # 80:20 split\n",
        "\n",
        "inputs_train =  inputs \n",
        "targets_train = targets \n",
        "originals_train = originals \n",
        "\n",
        "inputs_valid = validation_inputs \n",
        "targets_valid = validation_targets \n",
        "originals_valid = validation_originals \n",
        "\n",
        "\n",
        "dataset_train = SegmentationDataSet(inputs=inputs_train,\n",
        "                                    targets=targets_train,\n",
        "                                    originals= originals_train,\n",
        "                                    transform=None,\n",
        "                                    use_cache=True,\n",
        "                                    pre_transform=pre_transforms)\n",
        "\n",
        "# dataset validation\n",
        "dataset_valid = SegmentationDataSet(inputs=inputs_valid,\n",
        "                                    targets=targets_valid,\n",
        "                                    originals= originals_valid,\n",
        "                                    transform=None,\n",
        "                                    use_cache=True,\n",
        "                                    pre_transform=pre_transforms)\n",
        "\n",
        "# dataloader training\n",
        "dataloader_training = DataLoader(dataset=dataset_train,\n",
        "                                 batch_size=32,\n",
        "                                 shuffle=True)\n",
        "# dataloader validation\n",
        "dataloader_validation = DataLoader(dataset=dataset_valid,\n",
        "                                   batch_size=32,\n",
        "                                   shuffle=True)\n",
        "\n",
        "del originals_train\n",
        "del originals_valid\n",
        "del pre_transforms\n",
        "del targets_train\n",
        "del targets_valid\n",
        "del inputs_train\n",
        "del inputs_valid\n",
        "del dataset_train\n",
        "del dataset_valid\n",
        "\n",
        "del inputs\n",
        "del targets\n",
        "del originals\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPDcBqG8vJIH"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPfOr3MLkYEP"
      },
      "source": [
        "# training the model \n",
        "device = torch.device('cuda')\n",
        " \n",
        "model = UNetWithResnet50Encoder().to(device)\n",
        " \n",
        "# criterion\n",
        "criterion = torch.nn.MSELoss() #LogCoshLoss()\n",
        "\n",
        "\n",
        "\n",
        "# optimizer\n",
        "\n",
        "decoder_parameters = [item for module in model.up_blocks for item in module.parameters()]\n",
        "optimizer = torch.optim.Adam(decoder_parameters, lr=1e-4, weight_decay=1e-6)\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1)\n",
        "# lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=25, \n",
        "#                                                    max_lr=0.0001, epochs=150, steps_per_epoch=len(dataloader_training))\n",
        "\n",
        "scaler = GradScaler()  \n",
        "trainer_n = Trainer(model = model,\n",
        "                  device = device,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer,\n",
        "                  training_DataLoader = dataloader_training,\n",
        "                  validation_DataLoader = dataloader_validation,\n",
        "                  lr_scheduler = lr_scheduler,\n",
        "                  epochs = 150,\n",
        "                  accum_iter = 4,\n",
        "                  verbose_step = 1,\n",
        "                  EarlyStopping = 30,\n",
        "                  notebook = True,\n",
        "                  schd_batch_update = True,\n",
        "                  )\n",
        " \n",
        "\n",
        "# # start training\n",
        "training_losses, validation_losses, lr_rates = trainer_n.run_trainer()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(training_losses)\n",
        "plt.plot(validation_losses)\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper right')\n",
        "plt.show() \n",
        "\n",
        "del model, optimizer, dataloader_training, dataloader_validation, scaler, lr_scheduler\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Gthxjz5okP3A"
      },
      "source": [
        "# making predictions from the trained model (generating output images)\n",
        "device = torch.device('cuda')\n",
        "\n",
        "model = UNetWithResnet50Encoder().to(device)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Checkpoints/StyleTransferByUnet.pth')['model_state_dict'])\n",
        "\n",
        "# predict function \n",
        "def predict(img,\n",
        "            tar,\n",
        "            model,\n",
        "            preprocess,\n",
        "            postprocess,\n",
        "            device,\n",
        "            ):\n",
        "    model.eval()\n",
        "    img = preprocess(img)  # preprocess image\n",
        "    target = preprocess(tar)\n",
        "    x = img.unsqueeze(0).cuda() \n",
        "    y = target.unsqueeze(0).cuda()\n",
        "    with torch.no_grad():\n",
        "        out = model(x,y)  # send through model/network\n",
        "    result = postprocess(out)  # works better without relu\n",
        "\n",
        "    return result\n",
        "    \n",
        "#  making predictions\n",
        "\n",
        "root = pathlib.Path.cwd() / '/content/drive/MyDrive/Dataset_for_StyleTransferByUnet/validation_set' \n",
        "def get_filenames_of_path(path: pathlib.Path, ext: str = '*'):\n",
        "    \"\"\"Returns a list of files in a directory/path. Uses pathlib.\"\"\"\n",
        "    filenames = [file for file in path.glob(ext) if file.is_file()]\n",
        "    filenames.sort()   #= sorted(filenames)\n",
        "    # print(filenames)\n",
        "    return filenames\n",
        "    del filenames\n",
        "    \n",
        "# read images and store them in memory\n",
        "images = [Image.open(img_name) for img_name in get_filenames_of_path(root / 'input')]\n",
        "targets = [Image.open(tar_name) for tar_name in get_filenames_of_path(root / 'output')]\n",
        "origins = [Image.open(org_name) for org_name in get_filenames_of_path(root / 'style')]\n",
        "\n",
        "# preprocess function\n",
        "def preprocess(img):\n",
        "\n",
        "  \n",
        "  pre_transforms = transforms.Compose([\n",
        "        transforms.Resize((256,256)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "  img = pre_transforms(img)\n",
        "  return img\n",
        "  del img\n",
        "\n",
        "\n",
        "def inverse_normalize(tensor, mean, std):\n",
        "  for t, m, s in zip(tensor, mean, std):\n",
        "      t.mul_(s).add_(m)\n",
        "  return tensor\n",
        "\n",
        "\n",
        "# postprocess function\n",
        "def postprocess(img: torch.tensor):\n",
        "    \n",
        "  \n",
        "    inv_normalize = transforms.Normalize(\n",
        "      mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
        "      std=[1/0.229, 1/0.224, 1/0.225]\n",
        "    )\n",
        "\n",
        "    post_transforms = transforms.Normalize([0,0,0], [1,1,1])\n",
        "\n",
        "    normalize =  transforms.Compose([ transforms.Normalize([0,0,0], [1,1,1]),transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "    img = img.squeeze(0)  # (C,H,W)\n",
        "    img = torch.transpose(img,0,1) #(H,C,W)\n",
        "    img = torch.transpose(img,1,2) #(H,W,C)\n",
        "    img = img.cpu()\n",
        "    img = np.maximum(np.minimum(img.cpu().detach().numpy(),1.0),0.0)\n",
        "    img = (np.array(img) * 255).astype(np.uint8)\n",
        "    \n",
        "    return img\n",
        "    del img\n",
        "\n",
        "\n",
        "def preprocess_originals(img,\n",
        "            preprocess,\n",
        "            postprocess,\n",
        "            ):\n",
        "    model.eval()\n",
        "    img = preprocess(img)  # preprocess image\n",
        "    x = img.unsqueeze(0).cpu() \n",
        "    result = postprocess(x)  \n",
        "    return result\n",
        "\n",
        "output = [predict(img, targets[i], model, preprocess, postprocess, device) for i,img in enumerate(images)]\n",
        "origs = [preprocess_originals(img, preprocess, postprocess) for i,img in enumerate(origins)]\n",
        "\n",
        "for i in range(len(output)):\n",
        "    plt.figure(figsize=(16, 12))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.title(\"Output\")\n",
        "    plt.imshow(output[i])\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.title(\"Original\")\n",
        "    plt.imshow(origs[i])\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "p_transforms = transforms.Compose([\n",
        "    transforms.Resize((256,256)),\n",
        "])\n",
        "\n",
        "image_new = [p_transforms(img_name) for img_name in images]\n",
        "del images\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "target_new = [p_transforms(tar_name) for tar_name in targets]\n",
        "del targets\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "origin_new = [p_transforms(tar_name) for tar_name in origins]\n",
        "del origins\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWYVdn4avgaN"
      },
      "source": [
        "Display the Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3T5kYuV3vf3e"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import cv2 \n",
        "for i, im in enumerate(output):\n",
        "  \n",
        "  if i < 100:\n",
        "    fig, axes = plt.subplots(nrows=1,ncols=4,figsize=(15,15))\n",
        "    axes[0].imshow(image_new[i])\n",
        "    axes[1].imshow(target_new[i])\n",
        "    axes[2].imshow(origin_new[i])\n",
        "    axes[3].imshow(im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EG2pwRbevPOz"
      },
      "source": [
        "###Evaluation Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSb-QLowxsht"
      },
      "source": [
        "SSIM calculation function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WteXeiOCdkAi"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "from math import exp\n",
        "\n",
        "def gaussian(window_size, sigma):\n",
        "    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
        "    return gauss/gauss.sum()\n",
        "\n",
        "def create_window(window_size, channel):\n",
        "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
        "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
        "    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
        "    return window\n",
        "\n",
        "def _ssim(img1, img2, window, window_size, channel, size_average = True):\n",
        "    mu1 = F.conv2d(img1, window, padding = window_size//2, groups = channel)\n",
        "    mu2 = F.conv2d(img2, window, padding = window_size//2, groups = channel)\n",
        "\n",
        "    mu1_sq = mu1.pow(2)\n",
        "    mu2_sq = mu2.pow(2)\n",
        "    mu1_mu2 = mu1*mu2\n",
        "\n",
        "    sigma1_sq = F.conv2d(img1*img1, window, padding = window_size//2, groups = channel) - mu1_sq\n",
        "    sigma2_sq = F.conv2d(img2*img2, window, padding = window_size//2, groups = channel) - mu2_sq\n",
        "    sigma12 = F.conv2d(img1*img2, window, padding = window_size//2, groups = channel) - mu1_mu2\n",
        "\n",
        "    C1 = 0.01**2\n",
        "    C2 = 0.03**2\n",
        "\n",
        "    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n",
        "\n",
        "    if size_average:\n",
        "        return ssim_map.mean()\n",
        "    else:\n",
        "        return ssim_map.mean(1).mean(1).mean(1)\n",
        "\n",
        "class SSIM(torch.nn.Module):\n",
        "    def __init__(self, window_size = 11, size_average = True):\n",
        "        super(SSIM, self).__init__()\n",
        "        self.window_size = window_size\n",
        "        self.size_average = size_average\n",
        "        self.channel = 1\n",
        "        self.window = create_window(window_size, self.channel)\n",
        "\n",
        "    def forward(self, img1, img2):\n",
        "        (_, channel, _, _) = img1.size()\n",
        "\n",
        "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
        "            window = self.window\n",
        "        else:\n",
        "            window = create_window(self.window_size, channel)\n",
        "            \n",
        "            if img1.is_cuda:\n",
        "                window = window.cuda(img1.get_device())\n",
        "            window = window.type_as(img1)\n",
        "            \n",
        "            self.window = window\n",
        "            self.channel = channel\n",
        "\n",
        "\n",
        "        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n",
        "\n",
        "def ssim(img1, img2, window_size = 11, size_average = True):\n",
        "    (_, channel, _, _) = img1.size()\n",
        "    window = create_window(window_size, channel)\n",
        "    \n",
        "    if img1.is_cuda:\n",
        "        window = window.cuda(img1.get_device())\n",
        "    window = window.type_as(img1)\n",
        "    \n",
        "    return _ssim(img1, img2, window, window_size, channel, size_average)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Veesd1pzx1zU"
      },
      "source": [
        "PSNR calculation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LZgn9BWydyK"
      },
      "source": [
        "# psnr for pwct results\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2 \n",
        "from math import log10, sqrt\n",
        "import math \n",
        "import PIL\n",
        "psnr_values = []\n",
        "from PIL import Image\n",
        "image_dir = os.path.join('./train_new1/')   \n",
        "result_dir = os.path.join('./post_results_unet_input/')\n",
        "targets = [f for f in os.listdir(image_dir)]\n",
        "images = [f for f in os.listdir(result_dir)]\n",
        "\n",
        "print(targets)\n",
        "print(images)\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "def psnr(img1, img2):\n",
        "    mse = numpy.mean( (img1 - img2) ** 2 )\n",
        "    if mse == 0:\n",
        "      return 100\n",
        "    PIXEL_MAX = 255.0\n",
        "    return 20 * math.log10((PIXEL_MAX)/ sqrt(mse))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR-klJVbx-Ga"
      },
      "source": [
        "PSNR and SSIM calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWEzpmLqyz-f"
      },
      "source": [
        "psnr_values = []\n",
        "avgPSNR = 0\n",
        "for i in range(len(origin_new)):\n",
        "    im1 = tf.image.convert_image_dtype(origin_new[i], tf.float32)\n",
        "    output = output_model[i].squeeze(0)\n",
        "    output = output.cpu()\n",
        "    im2 = tf.image.convert_image_dtype(output, tf.float32)\n",
        "    psnr2 = tf.image.psnr(im1, im2, max_val=1.0)\n",
        "    avgPSNR += psnr2\n",
        "\n",
        "print(len(origin_new))\n",
        "print('Average PSNR = ', avgPSNR/len(origin_new))\n",
        "\n",
        "print(\"SSIM Values\")\n",
        "ssim_value = 0\n",
        "for i in range(len(origin_new)):\n",
        "    temp1 = torch.unsqueeze(origin_new[i],0)\n",
        "    temp2 = output_model[i].cpu() \n",
        "    ssim_value += ssim(temp1,temp2)\n",
        "print('Average SSIM = ', ssim_value/len(origin_new))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}